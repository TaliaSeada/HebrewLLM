[I 2024-05-19 09:42:52,955] A new study created in memory with name: no-name-5042048d-e39c-410e-b2ae-1493fc007aa9
Data Loaders created!
Epoch 1, Validation Loss: 0.3369
Epoch 2, Validation Loss: 0.3324
Epoch 3, Validation Loss: 0.3319
Epoch 4, Validation Loss: 0.3319
Epoch 5, Validation Loss: 0.3319
[I 2024-05-19 09:52:31,509] Trial 0 finished with value: 0.3318549767136574 and parameters: {'lr': 0.059398116791071494, 'batch_size': 64, 'num_layers': 4, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.4}. Best is trial 0 with value: 0.3318549767136574.
Data Loaders created!
Epoch 1, Validation Loss: 0.3312
Epoch 2, Validation Loss: 0.3314
Epoch 3, Validation Loss: 0.3315
Epoch 4, Validation Loss: 0.3313
Epoch 5, Validation Loss: 0.3313
[I 2024-05-19 10:09:01,799] Trial 1 finished with value: 0.33128985948860645 and parameters: {'lr': 0.01923519242049138, 'batch_size': 16, 'num_layers': 7, 'num_heads': 2, 'dim_feedforward': 16, 'dropout': 0.3}. Best is trial 1 with value: 0.33128985948860645.
C:\Users\orelz\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
Data Loaders created!
Epoch 1, Validation Loss: 0.8267
Epoch 2, Validation Loss: 0.7072
Epoch 3, Validation Loss: 0.6169
Epoch 4, Validation Loss: 0.5479
Epoch 5, Validation Loss: 0.4933
[I 2024-05-19 10:18:37,114] Trial 2 finished with value: 0.49327173829078674 and parameters: {'lr': 0.003392303911335658, 'batch_size': 128, 'num_layers': 3, 'num_heads': 1, 'dim_feedforward': 64, 'dropout': 0.4}. Best is trial 1 with value: 0.33128985948860645.
Data Loaders created!
Epoch 1, Validation Loss: 0.3813
Epoch 2, Validation Loss: 0.3321
Epoch 3, Validation Loss: 0.3324
Epoch 4, Validation Loss: 0.3321
Epoch 5, Validation Loss: 0.3316
[I 2024-05-19 10:30:39,104] Trial 3 finished with value: 0.33161094784736633 and parameters: {'lr': 0.0037960487317198425, 'batch_size': 16, 'num_layers': 3, 'num_heads': 2, 'dim_feedforward': 128, 'dropout': 0.2}. Best is trial 1 with value: 0.33128985948860645.
Data Loaders created!
Epoch 1, Validation Loss: 0.3335
Epoch 2, Validation Loss: 0.3318
Epoch 3, Validation Loss: 0.3272
Epoch 4, Validation Loss: 0.2832
Epoch 5, Validation Loss: 0.3010
[I 2024-05-19 10:39:34,512] Trial 4 finished with value: 0.30096298828721046 and parameters: {'lr': 0.08352968898237399, 'batch_size': 32, 'num_layers': 1, 'num_heads': 1, 'dim_feedforward': 128, 'dropout': 0.3}. Best is trial 4 with value: 0.30096298828721046.
Data Loaders created!
Epoch 1, Validation Loss: 0.3250
Epoch 2, Validation Loss: 0.2280
Epoch 3, Validation Loss: 0.2048
Epoch 4, Validation Loss: 0.2095
Epoch 5, Validation Loss: 0.2163
[I 2024-05-19 10:51:51,594] Trial 5 finished with value: 0.21631281543523073 and parameters: {'lr': 0.0034833523942181337, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 16, 'dropout': 0.3}. Best is trial 5 with value: 0.21631281543523073.
Data Loaders created!
Epoch 1, Validation Loss: 0.9719
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 10:54:05,297] Trial 6 pruned.    
Data Loaders created!
Epoch 1, Validation Loss: 0.8521
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 10:57:59,066] Trial 7 pruned.    
Data Loaders created!
Epoch 1, Validation Loss: 0.7448
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:00:59,553] Trial 8 pruned.    
Data Loaders created!
Epoch 1, Validation Loss: 0.9067
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:04:53,755] Trial 9 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.7462
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:07:01,059] Trial 10 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3222
Epoch 2, Validation Loss: 0.3306
Epoch 3, Validation Loss: 0.2600
Epoch 4, Validation Loss: 0.2520
Epoch 5, Validation Loss: 0.2514
[I 2024-05-19 11:19:03,589] Trial 11 finished with value: 0.25138770788908005 and parameters: {'lr': 0.0918097696816673, 'batch_size': 32, 'num_layers': 1, 'num_heads': 1, 'dim_feedforward': 128, 'dropout': 0.15}. Best is trial 5 with value: 0.21631281543523073.
Data Loaders created!
Epoch 1, Validation Loss: 0.2871
Epoch 2, Validation Loss: 0.2004
Epoch 3, Validation Loss: 0.1745
Epoch 4, Validation Loss: 0.1711
Epoch 5, Validation Loss: 0.1714
[I 2024-05-19 11:28:38,754] Trial 12 finished with value: 0.17140754498541355 and parameters: {'lr': 0.007716097470443623, 'batch_size': 32, 'num_layers': 1, 'num_heads': 1, 'dim_feedforward': 128, 'dropout': 0.15}. Best is trial 12 with value: 0.17140754498541355.
Data Loaders created!
Epoch 1, Validation Loss: 0.4315
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:30:49,434] Trial 13 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.5567
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:33:05,396] Trial 14 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3327
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:35:06,604] Trial 15 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 1.3753
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:37:06,613] Trial 16 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.6287
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:39:03,853] Trial 17 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.8686
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:40:59,137] Trial 18 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3314
Epoch 2, Validation Loss: 0.3311
Epoch 3, Validation Loss: 0.3315
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:48:23,703] Trial 19 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.7104
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 11:50:29,086] Trial 20 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2637
Epoch 2, Validation Loss: 0.2528
Epoch 3, Validation Loss: 0.2508
Epoch 4, Validation Loss: 0.2490
Epoch 5, Validation Loss: 0.2459
[I 2024-05-19 12:00:20,471] Trial 21 finished with value: 0.24594959057867527 and parameters: {'lr': 0.040027197848962914, 'batch_size': 32, 'num_layers': 1, 'num_heads': 1, 'dim_feedforward': 128, 'dropout': 0.15}. Best is trial 12 with value: 0.17140754498541355.
Data Loaders created!
Epoch 1, Validation Loss: 0.2775
Epoch 2, Validation Loss: 0.2963
Epoch 3, Validation Loss: 0.2694
Epoch 4, Validation Loss: 0.2834
Epoch 5, Validation Loss: 0.2467
[I 2024-05-19 12:09:23,798] Trial 22 finished with value: 0.2466521468013525 and parameters: {'lr': 0.023033740172196386, 'batch_size': 32, 'num_layers': 1, 'num_heads': 1, 'dim_feedforward': 128, 'dropout': 0.15}. Best is trial 12 with value: 0.17140754498541355.
Data Loaders created!
Epoch 1, Validation Loss: 0.4451
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:11:31,580] Trial 23 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2766
Epoch 2, Validation Loss: 0.2594
Epoch 3, Validation Loss: 0.2528
Epoch 4, Validation Loss: 0.2489
Epoch 5, Validation Loss: 0.2292
[I 2024-05-19 12:20:55,705] Trial 24 finished with value: 0.2291739583015442 and parameters: {'lr': 0.030749933437667503, 'batch_size': 32, 'num_layers': 1, 'num_heads': 1, 'dim_feedforward': 128, 'dropout': 0.15}. Best is trial 12 with value: 0.17140754498541355.
Data Loaders created!
Epoch 1, Validation Loss: 0.5197
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:23:13,742] Trial 25 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.6869
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:24:48,965] Trial 26 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.7532
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:26:53,583] Trial 27 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3702
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:29:05,781] Trial 28 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.3415
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:31:11,984] Trial 29 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.3313
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:33:39,334] Trial 30 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.3320
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:35:35,085] Trial 31 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2678
Epoch 2, Validation Loss: 0.2599
Epoch 3, Validation Loss: 0.2557
Epoch 4, Validation Loss: 0.2528
Epoch 5, Validation Loss: 0.2524
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 12:47:16,141] Trial 32 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.1883
Epoch 2, Validation Loss: 0.1223
Epoch 3, Validation Loss: 0.1105
Epoch 4, Validation Loss: 0.1095
Epoch 5, Validation Loss: 0.1237
[I 2024-05-19 12:59:19,652] Trial 33 finished with value: 0.12374380510300398 and parameters: {'lr': 0.013256841285324495, 'batch_size': 32, 'num_layers': 1, 'num_heads': 1, 'dim_feedforward': 128, 'dropout': 0.15}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.3365
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 13:01:32,407] Trial 34 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.5814
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 13:05:54,127] Trial 35 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.7822
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 13:07:38,432] Trial 36 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.6546
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 13:10:50,747] Trial 37 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3330
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 13:13:17,057] Trial 38 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2836
Epoch 2, Validation Loss: 0.2111
Epoch 3, Validation Loss: 0.2039
Epoch 4, Validation Loss: 0.2151
Epoch 5, Validation Loss: 0.1995
[I 2024-05-19 13:24:44,914] Trial 39 finished with value: 0.1995273968204856 and parameters: {'lr': 0.00360352184255398, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.15}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.7338
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 13:27:50,971] Trial 40 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2515
Epoch 2, Validation Loss: 0.2166
Epoch 3, Validation Loss: 0.2030
Epoch 4, Validation Loss: 0.1789
Epoch 5, Validation Loss: 0.1768
[I 2024-05-19 13:38:21,537] Trial 41 finished with value: 0.17679026164114475 and parameters: {'lr': 0.004138746605058311, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.15}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2640
Epoch 2, Validation Loss: 0.2110
Epoch 3, Validation Loss: 0.2035
Epoch 4, Validation Loss: 0.1984
Epoch 5, Validation Loss: 0.1953
[I 2024-05-19 13:48:51,327] Trial 42 finished with value: 0.19534999877214432 and parameters: {'lr': 0.003510866391458512, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.15}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2408
Epoch 2, Validation Loss: 0.1858
Epoch 3, Validation Loss: 0.1772
Epoch 4, Validation Loss: 0.1814
Epoch 5, Validation Loss: 0.1788
[I 2024-05-19 13:59:23,370] Trial 43 finished with value: 0.17881452292203903 and parameters: {'lr': 0.0035205787892697705, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.15}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.4328
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:01:28,513] Trial 44 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3533
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:03:47,530] Trial 45 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.4462
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:06:19,201] Trial 46 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.8412
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:09:01,190] Trial 47 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.6925
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:11:13,410] Trial 48 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.5724
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:13:17,305] Trial 49 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.7333
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:15:05,578] Trial 50 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2700
Epoch 2, Validation Loss: 0.2294
Epoch 3, Validation Loss: 0.2481
Epoch 4, Validation Loss: 0.2449
Epoch 5, Validation Loss: 0.2433
[I 2024-05-19 14:26:19,385] Trial 51 finished with value: 0.2433208441361785 and parameters: {'lr': 0.0042118266805915155, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.15}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.5098
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:28:24,798] Trial 52 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2726
Epoch 2, Validation Loss: 0.2500
Epoch 3, Validation Loss: 0.2497
Epoch 4, Validation Loss: 0.2499
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:37:06,864] Trial 53 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3667
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:39:13,983] Trial 54 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.4956
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:40:58,717] Trial 55 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2642
Epoch 2, Validation Loss: 0.2049
Epoch 3, Validation Loss: 0.2012
Epoch 4, Validation Loss: 0.1989
Epoch 5, Validation Loss: 0.1972
[I 2024-05-19 14:51:31,689] Trial 56 finished with value: 0.19721690379083157 and parameters: {'lr': 0.0036111794394128975, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.3313
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 14:53:47,030] Trial 57 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2361
Epoch 2, Validation Loss: 0.1969
Epoch 3, Validation Loss: 0.1944
Epoch 4, Validation Loss: 0.1930
Epoch 5, Validation Loss: 0.1948
[I 2024-05-19 15:06:49,382] Trial 58 finished with value: 0.19479614030569792 and parameters: {'lr': 0.01223645583220073, 'batch_size': 16, 'num_layers': 1, 'nm_layers': 1, 'num_heads': 2, 'dim_feedforward': 256, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2080
Epoch 2, Validation Loss: 0.1808
Epoch 3, Validation Loss: 0.1724
Epoch 4, Validation Loss: 0.1702
Epoch 5, Validation Loss: 0.1892
[I 2024-05-19 15:18:30,581] Trial 59 finished with value: 0.18923364114016294 and parameters: {'lr': 0.014908294918947051, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 256, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.4790
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 15:21:11,291] Trial 60 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2222
Epoch 2, Validation Loss: 0.2192
Epoch 3, Validation Loss: 0.1877
Epoch 4, Validation Loss: 0.1872
Epoch 5, Validation Loss: 0.2014
[I 2024-05-19 15:36:44,977] Trial 61 finished with value: 0.2013631472364068 and parameters: {'lr': 0.011500406376956424, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 256, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2454
Epoch 2, Validation Loss: 0.2124
Epoch 3, Validation Loss: 0.2038
Epoch 4, Validation Loss: 0.1845
Epoch 5, Validation Loss: 0.1709
[I 2024-05-19 16:01:39,653] Trial 62 finished with value: 0.17087594605982304 and parameters: {'lr': 0.006618728432754259, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 256, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2037
Epoch 2, Validation Loss: 0.1875
Epoch 3, Validation Loss: 0.1763
Epoch 4, Validation Loss: 0.1591
Epoch 5, Validation Loss: 0.1761
[I 2024-05-19 16:26:02,726] Trial 63 finished with value: 0.1761239990592003 and parameters: {'lr': 0.007454767432622232, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 256, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2562
Epoch 2, Validation Loss: 0.2145
Epoch 3, Validation Loss: 0.2261
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 16:37:51,101] Trial 64 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3418
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 16:41:08,831] Trial 65 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 1.3153
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 16:43:21,876] Trial 66 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3313
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 16:45:46,333] Trial 67 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2750
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 16:47:39,430] Trial 68 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3338
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 16:50:24,304] Trial 69 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3408
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 16:52:26,368] Trial 70 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2380
Epoch 2, Validation Loss: 0.2097
Epoch 3, Validation Loss: 0.2042
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 16:59:47,313] Trial 71 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2319
Epoch 2, Validation Loss: 0.2502
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:04:20,544] Trial 72 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2094
Epoch 2, Validation Loss: 0.1963
Epoch 3, Validation Loss: 0.1997
Epoch 4, Validation Loss: 0.1908
Epoch 5, Validation Loss: 0.2308
[I 2024-05-19 17:15:56,477] Trial 73 finished with value: 0.23082622047513723 and parameters: {'lr': 0.005296275510911432, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 256, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2522
Epoch 2, Validation Loss: 0.2330
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:20:33,609] Trial 74 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.2365
Epoch 2, Validation Loss: 0.2106
Epoch 3, Validation Loss: 0.2331
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:27:22,551] Trial 75 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3318
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:29:50,539] Trial 76 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.6008
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:31:47,925] Trial 77 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.3492
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:33:35,939] Trial 78 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.6193
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:35:26,107] Trial 79 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2182
Epoch 2, Validation Loss: 0.2044
Epoch 3, Validation Loss: 0.2267
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:42:29,875] Trial 80 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2970
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:44:42,983] Trial 81 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.4893
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 17:46:57,908] Trial 82 pruned. 
Data Loaders created!
Epoch 1, Validation Loss: 0.2502
Epoch 2, Validation Loss: 0.2055
Epoch 3, Validation Loss: 0.1946
Epoch 4, Validation Loss: 0.1806
Epoch 5, Validation Loss: 0.1985
[I 2024-05-19 17:58:12,150] Trial 83 finished with value: 0.19852023478597403 and parameters: {'lr': 0.004283704937589438, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 128, 'dropout': 0.15}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2502
Epoch 2, Validation Loss: 0.2215
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:02:44,437] Trial 84 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.4368
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:04:55,235] Trial 85 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2555
Epoch 2, Validation Loss: 0.2570
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:09:54,381] Trial 86 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.3799
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:12:13,330] Trial 87 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.4863
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:14:32,967] Trial 88 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.5547
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:16:46,706] Trial 89 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3327
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:20:13,785] Trial 90 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.2594
Epoch 2, Validation Loss: 0.2381
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:24:42,286] Trial 91 pruned.   
Data Loaders created!
Epoch 1, Validation Loss: 0.2886
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:27:08,971] Trial 92 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2565
Epoch 2, Validation Loss: 0.2110
Epoch 3, Validation Loss: 0.1900
Epoch 4, Validation Loss: 0.1850
Epoch 5, Validation Loss: 0.1809
[I 2024-05-19 18:38:23,778] Trial 93 finished with value: 0.18093166127800941 and parameters: {'lr': 0.006598998317178377, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2179
Epoch 2, Validation Loss: 0.1976
Epoch 3, Validation Loss: 0.1963
Epoch 4, Validation Loss: 0.1927
Epoch 5, Validation Loss: 0.1918
[I 2024-05-19 18:49:35,804] Trial 94 finished with value: 0.19181573018431664 and parameters: {'lr': 0.006269714407665733, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 32, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.2589
Epoch 2, Validation Loss: 0.2506
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 18:54:13,433] Trial 95 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.2514
Epoch 2, Validation Loss: 0.1996
Epoch 3, Validation Loss: 0.1939
Epoch 4, Validation Loss: 0.1908
Epoch 5, Validation Loss: 0.2064
[I 2024-05-19 19:05:25,029] Trial 96 finished with value: 0.20635402109473944 and parameters: {'lr': 0.013795256005161903, 'batch_size': 16, 'num_layers': 1, 'num_heads': 2, 'dim_feedforward': 16, 'dropout': 0.1}. Best is trial 33 with value: 0.12374380510300398.
Data Loaders created!
Epoch 1, Validation Loss: 0.3326
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 19:07:35,912] Trial 97 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.6905
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 19:10:01,212] Trial 98 pruned.
Data Loaders created!
Epoch 1, Validation Loss: 0.3540
/n/n==========its because of me!!==========/n/n
[I 2024-05-19 19:11:46,203] Trial 99 pruned. 
{'lr': 0.013256841285324495, 'batch_size': 32, 'num_layers': 1, 'num_heads': 1, 'dim_feedforward': 128, 'dropout': 0.15}